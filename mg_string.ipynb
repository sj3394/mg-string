{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N684vdTRNXab"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1. Imports\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52noT1-KOQ0Q",
        "outputId": "3a22b037-78e6-4270-d2fb-9c5d843d4155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "2. Configs\n",
        "\"\"\"\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    dataset: str = \"CIFAR10\"  # \"MNIST\" or \"CIFAR10\"\n",
        "    data_root: str = \"./data\"\n",
        "    batch_size: int = 128\n",
        "    img_size: int = 32\n",
        "    patch_size: int = 4\n",
        "    num_classes: int = 10\n",
        "\n",
        "    dim: int = 256          # model dimension\n",
        "    num_heads: int = 4\n",
        "    depth: int = 6          # number of Transformer layers\n",
        "    dropout: float = 0.1\n",
        "\n",
        "    max_epochs: int = 50\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "\n",
        "    # checkpoint\n",
        "    ckpt_dir: str = \"./checkpoints\"\n",
        "    save_every: int = 1     # save every N epochs\n",
        "\n",
        "    # positional encoding\n",
        "    max_seq_len: int = 256\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "os.makedirs(cfg.ckpt_dir, exist_ok=True)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cfg.ckpt_dir = \"/content/drive/MyDrive/E6617_final_project/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ObSi6FpoOXhL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "3. Data: MNIST / CIFAR-10\n",
        "\"\"\"\n",
        "\n",
        "def get_dataloaders(cfg: Config):\n",
        "    if cfg.dataset.upper() == \"MNIST\":\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(cfg.img_size),\n",
        "            transforms.ToTensor(),\n",
        "            # MNIST is 1-ch; expand to 3-ch\n",
        "            transforms.Lambda(lambda x: x.expand(3, -1, -1)),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                 (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "        train_dataset = datasets.MNIST(\n",
        "            root=cfg.data_root, train=True, download=True, transform=transform\n",
        "        )\n",
        "        test_dataset = datasets.MNIST(\n",
        "            root=cfg.data_root, train=False, download=True, transform=transform\n",
        "        )\n",
        "    elif cfg.dataset.upper() == \"CIFAR10\":\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(cfg.img_size, scale=(0.8, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                 (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "\n",
        "        test_transform = transforms.Compose([\n",
        "            transforms.Resize(cfg.img_size),\n",
        "            transforms.CenterCrop(cfg.img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                 (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "\n",
        "        train_dataset = datasets.CIFAR10(\n",
        "            root=cfg.data_root, train=True, download=True,\n",
        "            transform=train_transform\n",
        "        )\n",
        "        test_dataset = datasets.CIFAR10(\n",
        "            root=cfg.data_root, train=False, download=True,\n",
        "            transform=test_transform\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported dataset\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size,\n",
        "                              shuffle=True, num_workers=2, pin_memory=True,\n",
        "                              persistent_workers=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size,\n",
        "                             shuffle=False, num_workers=2, pin_memory=True,\n",
        "                             persistent_workers=True)\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JCbma5Z7ObPS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4. Positional Encoding Utilities\n",
        ">> 4.1 RoPE (Rotary)\n",
        ">> 4.2 Cayley-STRING / MG-STRING\n",
        "\"\"\"\n",
        "\n",
        "# 4.1 RoPE\n",
        "\n",
        "def build_rope_freqs(head_dim: int, max_seq_len: int, device):\n",
        "    half_dim = head_dim // 2\n",
        "    theta = torch.arange(half_dim, device=device, dtype=torch.float32)\n",
        "    theta = 1.0 / (10000 ** (theta / half_dim))\n",
        "    positions = torch.arange(max_seq_len, device=device, dtype=torch.float32)\n",
        "    freqs = torch.einsum('p,f->pf', positions, theta)  # [max_seq_len, half_dim]\n",
        "    cos = freqs.cos()\n",
        "    sin = freqs.sin()\n",
        "    return cos, sin  # [max_seq_len, half_dim]\n",
        "\n",
        "\n",
        "def apply_rope(q, k, cos, sin, seq_len):\n",
        "    # q,k: [B, H, N, D], D even\n",
        "    # cos,sin: [max_seq_len, D/2];\n",
        "    B, H, N, D = q.shape\n",
        "    assert D % 2 == 0\n",
        "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # [1,1,N,D/2]\n",
        "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)  # [1,1,N,D/2]\n",
        "\n",
        "    def rotate(x):\n",
        "        x1, x2 = x[..., :D//2], x[..., D//2:]\n",
        "        # rotary: (x1, x2) -> (x1*cos - x2*sin, x2*cos + x1*sin)\n",
        "        x1_new = x1 * cos - x2 * sin\n",
        "        x2_new = x2 * cos + x1 * sin\n",
        "        return torch.cat([x1_new, x2_new], dim=-1)\n",
        "\n",
        "    return rotate(q), rotate(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "T39P0OSSOfLa"
      },
      "outputs": [],
      "source": [
        "# 4.2 Cayley-based PE (single & multi-generator)\n",
        "\n",
        "class CayleyPE(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements A(p) = sum_l rho_l(p) S_l  with S_l skew-symmetric,\n",
        "    then R(p) = Cayley(A(p)) = (I - A)(I + A)^{-1}, applied per position.\n",
        "    - L = 1: Cayley-STRING style\n",
        "    - L > 1: multi-generator (MG-STRING)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        head_dim: int,\n",
        "        max_seq_len: int,\n",
        "        num_generators: int = 1,\n",
        "        sparse: bool = False,\n",
        "        sparsity_band: int | None = None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_dim = head_dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.num_generators = num_generators\n",
        "\n",
        "        self.register_buffer(\n",
        "            \"I\",\n",
        "            torch.eye(head_dim, dtype=torch.float32),\n",
        "            persistent=False,\n",
        "        )\n",
        "\n",
        "        # unconstrained parameters that become skew-symmetric\n",
        "        self.L_list = nn.ParameterList([\n",
        "            nn.Parameter(torch.randn(head_dim, head_dim) * 1e-4)\n",
        "            for _ in range(num_generators)\n",
        "        ])\n",
        "\n",
        "        # simple learnable scalar per generator\n",
        "        self.rho_scale = nn.Parameter(torch.ones(num_generators))\n",
        "\n",
        "        self.sparse = sparse\n",
        "        D = head_dim\n",
        "\n",
        "        if self.sparse:\n",
        "            idx = torch.arange(D)\n",
        "\n",
        "            if sparsity_band is None:\n",
        "                band = max(1, D // 4)\n",
        "            else:\n",
        "                band = max(1, sparsity_band)\n",
        "\n",
        "            mask = (idx[None, :] - idx[:, None]).abs() <= band\n",
        "            mask = mask.to(torch.float32)\n",
        "\n",
        "            mask.fill_diagonal_(0.0)\n",
        "\n",
        "            self.register_buffer(\n",
        "                \"sparsity_mask\",\n",
        "                mask,\n",
        "                persistent=False,\n",
        "            )\n",
        "        else:\n",
        "            # dense\n",
        "            self.register_buffer(\n",
        "                \"sparsity_mask\",\n",
        "                torch.ones(D, D),\n",
        "                persistent=False,\n",
        "            )\n",
        "\n",
        "    def forward(self, q, k, pos_ids):\n",
        "        \"\"\"\n",
        "        q, k: [B, H, N, D]\n",
        "        pos_ids: [N] or [B,N] integer positions in [0, max_seq_len)\n",
        "        \"\"\"\n",
        "        device = q.device\n",
        "        B, H, N, D = q.shape\n",
        "        assert D == self.head_dim\n",
        "\n",
        "        # normalize pos to [0,1]\n",
        "        if pos_ids.dim() == 2:\n",
        "            # assume [B,N], but we only support same positions per batch\n",
        "            pos_ids = pos_ids[0]\n",
        "        pos_float = pos_ids.to(q.dtype) / float(self.max_seq_len)        # [N]\n",
        "\n",
        "        S_list: list[torch.Tensor] = []\n",
        "        for Lmat in self.L_list:\n",
        "            S_dense = Lmat - Lmat.T                 # [D, D], skew-symmetric\n",
        "            S_sparse = S_dense * self.sparsity_mask # apply fixed sparsity pattern\n",
        "            # Normalize S_l\n",
        "            norm = S_sparse.norm(p='fro') + 1e-6\n",
        "            S_sparse = S_sparse / norm\n",
        "            S_list.append(S_sparse)\n",
        "\n",
        "        # S: [L, D, D]\n",
        "        S = torch.stack(S_list, dim=0)\n",
        "\n",
        "        # rho_l(p) = w_l * p_norm\n",
        "        rho_l = torch.clamp(self.rho_scale, -2.0, 2.0)\n",
        "        rho = rho_l[None, :, None, None] * pos_float[:, None, None, None]  # [N,L,1,1]\n",
        "        A = (rho * S[None, ...]).sum(dim=1)                              # [N,D,D]\n",
        "\n",
        "        I = self.I.to(dtype=q.dtype, device=device)\n",
        "        I_plus  = I + A                                                  # [N,D,D]\n",
        "        I_minus = I - A                                                  # [N,D,D]\n",
        "\n",
        "        epsI = 1e-3 * I\n",
        "        R_stack = torch.linalg.solve(I_plus + epsI, I_minus)\n",
        "\n",
        "        # Apply R(p) to each position's q,k: new_q[p] = R_p @ q[p]\n",
        "        q_rot = torch.einsum('pij,bhpj->bhpi', R_stack, q)\n",
        "        k_rot = torch.einsum('pij,bhpj->bhpi', R_stack, k)\n",
        "        return q_rot, k_rot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kjzKw7YSOh6F"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "5. Model: Patch Embedding + Transformer + Head\n",
        "\"\"\"\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size, patch_size, in_chans=3, embed_dim=256):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.grid_size = img_size // patch_size\n",
        "        self.num_patches = self.grid_size * self.grid_size\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim,\n",
        "                              kernel_size=patch_size,\n",
        "                              stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,3,H,W] -> [B, N, D]\n",
        "        x = self.proj(x)  # [B,D,H',W']\n",
        "        x = x.flatten(2).transpose(1, 2)  # [B, N, D]\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads,\n",
        "                 pe_type: str = \"rope\",\n",
        "                 max_seq_len: int = 256,\n",
        "                 num_generators: int = 1,\n",
        "                 sparsity_band: int | None = None):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.pe_type = pe_type\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.sparsity_band = sparsity_band\n",
        "\n",
        "        self.register_buffer(\n",
        "            \"pos_ids_buffer\",\n",
        "            torch.arange(max_seq_len, dtype=torch.long),\n",
        "            persistent=False,\n",
        "        )\n",
        "\n",
        "        # Use for \"rope\" and as baseline for others\n",
        "        if pe_type in [\"rope\", \"cayley\", \"cayley_sparse\", \"mg\", \"mg_sparse\"]:\n",
        "            cos, sin = build_rope_freqs(self.head_dim, max_seq_len,\n",
        "                                        device=cfg.device)\n",
        "            self.register_buffer(\"rope_cos\", cos, persistent=False)\n",
        "            self.register_buffer(\"rope_sin\", sin, persistent=False)\n",
        "        else:\n",
        "            self.register_buffer(\"rope_cos\", None, persistent=False)\n",
        "            self.register_buffer(\"rope_sin\", None, persistent=False)\n",
        "\n",
        "        # Cayley or MG-STRING\n",
        "        if pe_type in [\"cayley\", \"mg\", \"cayley_sparse\", \"mg_sparse\"]:\n",
        "            gens = num_generators if pe_type in [\"mg\", \"mg_sparse\"] else 1\n",
        "            use_sparse = pe_type in [\"cayley_sparse\", \"mg_sparse\"]\n",
        "            self.cayley_pe = CayleyPE(\n",
        "                self.head_dim,\n",
        "                max_seq_len,\n",
        "                gens,\n",
        "                sparse=use_sparse,\n",
        "                sparsity_band=self.sparsity_band,\n",
        "            )\n",
        "        else:\n",
        "            self.cayley_pe = None\n",
        "\n",
        "        if pe_type in [\"mg\", \"mg_sparse\"]:\n",
        "            # small positive init so it starts close to RoPE\n",
        "            init_alpha = 0.23\n",
        "            init_logit = torch.log(torch.tensor(init_alpha / (1 - init_alpha)))\n",
        "            self.mg_alpha = nn.Parameter(init_logit)\n",
        "        else:\n",
        "            self.mg_alpha = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, D]\n",
        "        B, N, D = x.shape\n",
        "\n",
        "        qkv = self.qkv(x)  # [B, N, 3*D]\n",
        "        qkv = qkv.reshape(B, N, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)  # [3,B,H,N,D]\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]  # [B,H,N,D]\n",
        "\n",
        "        if self.pe_type in [\"rope\", \"cayley\", \"cayley_sparse\", \"mg\", \"mg_sparse\"]:\n",
        "            q, k = apply_rope(q, k, self.rope_cos, self.rope_sin, N)\n",
        "\n",
        "        # After q,k have RoPE applied\n",
        "        if self.pe_type in [\"cayley\", \"mg\", \"cayley_sparse\", \"mg_sparse\"]:\n",
        "            # 1) Cayley-STRING base with position-independent P\n",
        "            pos_ids_const = self.pos_ids_buffer.new_full(\n",
        "                (N,),\n",
        "                self.max_seq_len - 1,\n",
        "                dtype=self.pos_ids_buffer.dtype,\n",
        "            )\n",
        "            q_base, k_base = self.cayley_pe(q, k, pos_ids_const)  # Cayley-STRING\n",
        "\n",
        "            if self.pe_type in [\"cayley\", \"cayley_sparse\"]:\n",
        "                # used as is\n",
        "                q, k = q_base, k_base\n",
        "            else:\n",
        "                # 2) MG part: position-dependent multi-generator Cayley\n",
        "                pos_ids_full = self.pos_ids_buffer[:N]\n",
        "                q_mg, k_mg = self.cayley_pe(q, k, pos_ids_full)\n",
        "\n",
        "                # 3) MG-STRING = Cayley-STRING + residual towards position-dependent version\n",
        "                alpha = torch.sigmoid(self.mg_alpha)  # (0,1)\n",
        "\n",
        "                q = q_base + alpha * (q_mg - q_base)\n",
        "                k = k_base + alpha * (k_mg - k_base)\n",
        "\n",
        "        attn_scores = (q @ k.transpose(-2, -1)) * self.scale  # [B,H,N,N]\n",
        "        attn = attn_scores.softmax(dim=-1)\n",
        "        out = attn @ v  # [B,H,N,D]\n",
        "\n",
        "        out = out.transpose(1, 2).reshape(B, N, D)\n",
        "        out = self.proj(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4.0, dropout=0.1,\n",
        "                 pe_type=\"rope\", max_seq_len=256, num_generators=1):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = MultiHeadSelfAttention(\n",
        "            dim, num_heads, pe_type=pe_type,\n",
        "            max_seq_len=max_seq_len,\n",
        "            num_generators=num_generators,\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class ViTWithPE(nn.Module):\n",
        "    def __init__(self, cfg: Config,\n",
        "                 pe_type: str = \"rope\",\n",
        "                 num_generators: int = 1):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.pe_type = pe_type\n",
        "        self.num_generators = num_generators\n",
        "\n",
        "        self.patch_embed = PatchEmbed(\n",
        "            img_size=cfg.img_size,\n",
        "            patch_size=cfg.patch_size,\n",
        "            in_chans=3,\n",
        "            embed_dim=cfg.dim,\n",
        "        )\n",
        "        self.num_patches = self.patch_embed.num_patches\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, cfg.dim))\n",
        "        self.pos_drop = nn.Dropout(cfg.dropout)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(\n",
        "                dim=cfg.dim,\n",
        "                num_heads=cfg.num_heads,\n",
        "                mlp_ratio=4.0,\n",
        "                dropout=cfg.dropout,\n",
        "                pe_type=pe_type,\n",
        "                max_seq_len=self.num_patches + 1,\n",
        "                num_generators=num_generators,\n",
        "            )\n",
        "            for _ in range(cfg.depth)\n",
        "        ])\n",
        "\n",
        "        self.norm = nn.LayerNorm(cfg.dim)\n",
        "        self.head = nn.Linear(cfg.dim, cfg.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,3,H,W]\n",
        "        B = x.size(0)\n",
        "        x = self.patch_embed(x)  # [B, N, D]\n",
        "        N = x.size(1)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)  # [B,1,D]\n",
        "        x = torch.cat([cls_tokens, x], dim=1)  # [B, N+1, D]\n",
        "\n",
        "        x = self.pos_drop(x)\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        cls_out = x[:, 0]  # [B,D]\n",
        "        logits = self.head(cls_out)\n",
        "        return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PdZ_KAZBOntx"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "6. Training / Evaluation / Checkpoint Utils\n",
        "\"\"\"\n",
        "\n",
        "def save_checkpoint(path, model, optimizer, epoch, best_acc):\n",
        "    state = {\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optim_state\": optimizer.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"best_acc\": best_acc,\n",
        "    }\n",
        "    torch.save(state, path)\n",
        "    print(f\"[Checkpoint] Saved at epoch {epoch} to {path}\")\n",
        "\n",
        "\n",
        "def load_checkpoint(path, model, optimizer, device, strict_model=False, load_optim=False):\n",
        "    ckpt = torch.load(path, map_location=device)\n",
        "\n",
        "    # 1) Load model\n",
        "    try:\n",
        "        msg = model.load_state_dict(ckpt[\"model_state\"], strict=strict_model)\n",
        "        if not strict_model:\n",
        "            print(\"[Checkpoint] Loaded with strict=False\")\n",
        "            print(\"    Missing / unexpected keys:\", msg)\n",
        "    except RuntimeError as e:\n",
        "        print(\"[Checkpoint] Model state_dict mismatch:\")\n",
        "        print(\"   \", e)\n",
        "        print(\"[Checkpoint] Starting from scratch for model.\")\n",
        "        return 0, 0.0\n",
        "\n",
        "    start_epoch = ckpt.get(\"epoch\", -1) + 1\n",
        "    best_acc = ckpt.get(\"best_acc\", 0.0)\n",
        "\n",
        "    # 2) Load optimizer\n",
        "    if load_optim:\n",
        "        try:\n",
        "            optimizer.load_state_dict(ckpt[\"optim_state\"])\n",
        "        except Exception as e:\n",
        "            print(\"[Checkpoint] Optimizer state mismatch, reinitializing optimizer.\")\n",
        "            print(\"   \", e)\n",
        "            start_epoch = 0\n",
        "            best_acc = 0.0\n",
        "\n",
        "    return start_epoch, best_acc\n",
        "\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_sum = 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device == \"cuda\")):\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                logits = model(images)\n",
        "                loss = criterion(logits, labels)\n",
        "                loss_sum += loss.item() * labels.size(0)\n",
        "                preds = logits.argmax(dim=-1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "\n",
        "# Relative-Position Metrics\n",
        "def compute_relative_position_metrics(cayley_pe, max_positions=64, n_attn_samples=500):\n",
        "    \"\"\"\n",
        "    Computes:\n",
        "      - relative rotation error (mean, max)\n",
        "      - commutator norms (mean, max) if L>1\n",
        "      - orthogonality error (mean, max)\n",
        "      - smoothness (mean)\n",
        "      - attention relative error (mean)\n",
        "    \"\"\"\n",
        "    device = cayley_pe.rho_scale.device\n",
        "    D = cayley_pe.head_dim\n",
        "    N = min(max_positions, cayley_pe.max_seq_len)\n",
        "\n",
        "    S_list = []\n",
        "    for Lmat in cayley_pe.L_list:\n",
        "        S = (Lmat - Lmat.T).detach()\n",
        "        if hasattr(cayley_pe, \"sparsity_mask\") and cayley_pe.sparsity_mask is not None:\n",
        "            S = S * cayley_pe.sparsity_mask.detach()\n",
        "        S_list.append(S)\n",
        "\n",
        "    pos_ids = torch.arange(N, device=device, dtype=torch.float32)\n",
        "    pos_norm = pos_ids / float(cayley_pe.max_seq_len)\n",
        "    I = torch.eye(D, device=device)\n",
        "    R_list = []\n",
        "    for pi in pos_norm:\n",
        "        if cayley_pe.num_generators == 1:\n",
        "            A_p = cayley_pe.rho_scale[0] * pi * S_list[0]\n",
        "        else:\n",
        "            A_p = torch.zeros_like(S_list[0])\n",
        "            for l, S in enumerate(S_list):\n",
        "                A_p = A_p + cayley_pe.rho_scale[l] * pi * S\n",
        "        R_p = torch.linalg.solve(I + A_p, I - A_p)\n",
        "        R_list.append(R_p.detach())\n",
        "    R_list = torch.stack(R_list, dim=0)  # [N,D,D]\n",
        "\n",
        "    # Metric 1: Relative rotation error\n",
        "    rel_errors = []\n",
        "    for i in range(N):\n",
        "        for j in range(i + 1, N):\n",
        "            delta = j - i\n",
        "            if delta >= N:\n",
        "                continue\n",
        "            R_rel_ideal = R_list[delta]           # R(p_j - p_i)\n",
        "            R_rel_actual = R_list[i].T @ R_list[j]\n",
        "            rel = torch.norm(R_rel_actual - R_rel_ideal, p='fro').item()\n",
        "            rel_errors.append(rel)\n",
        "    rel_mean = float(sum(rel_errors) / len(rel_errors)) if rel_errors else None\n",
        "    rel_max = float(max(rel_errors)) if rel_errors else None\n",
        "\n",
        "    # Metric 2: Commutator norms (Abelianity)\n",
        "    comm_vals = []\n",
        "    Lg = len(S_list)\n",
        "    if Lg > 1:\n",
        "        for i in range(Lg):\n",
        "            for j in range(i + 1, Lg):\n",
        "                comm = S_list[i] @ S_list[j] - S_list[j] @ S_list[i]\n",
        "                comm_vals.append(torch.norm(comm, p='fro').item())\n",
        "        comm_mean = float(sum(comm_vals) / len(comm_vals))\n",
        "        comm_max = float(max(comm_vals))\n",
        "    else:\n",
        "        comm_mean = None\n",
        "        comm_max = None\n",
        "\n",
        "    # Metric 3: Orthogonality error\n",
        "    ortho_vals = []\n",
        "    for R in R_list:\n",
        "        ortho_vals.append(torch.norm(R.T @ R - I, p='fro').item())\n",
        "    ortho_mean = float(sum(ortho_vals) / len(ortho_vals))\n",
        "    ortho_max = float(max(ortho_vals))\n",
        "\n",
        "    # Metric 4: Smoothness (adjacent rotation distance)\n",
        "    smooth_vals = []\n",
        "    for i in range(N - 1):\n",
        "        smooth_vals.append(torch.norm(R_list[i + 1] - R_list[i], p='fro').item())\n",
        "    smooth_mean = float(sum(smooth_vals) / len(smooth_vals)) if smooth_vals else None\n",
        "\n",
        "    # Metric 5: Attention-relative error\n",
        "    attn_errors = []\n",
        "    for _ in range(n_attn_samples):\n",
        "        q = torch.randn(D, device=device)\n",
        "        k = torch.randn(D, device=device)\n",
        "        i = torch.randint(0, N - 1, (1,)).item()\n",
        "        j = torch.randint(i + 1, N, (1,)).item()\n",
        "        actual = (R_list[i] @ q).dot(R_list[j] @ k)\n",
        "        ideal = (R_list[j - i] @ q).dot(k)\n",
        "        attn_errors.append(float(abs(actual - ideal).item()))\n",
        "    attn_mean = float(sum(attn_errors) / len(attn_errors))\n",
        "\n",
        "    metrics = {\n",
        "        \"rel_rot_error_mean\": rel_mean,\n",
        "        \"rel_rot_error_max\": rel_max,\n",
        "        \"comm_mean\": comm_mean,\n",
        "        \"comm_max\": comm_max,\n",
        "        \"ortho_error_mean\": ortho_mean,\n",
        "        \"ortho_error_max\": ortho_max,\n",
        "        \"smoothness_mean\": smooth_mean,\n",
        "        \"attn_rel_error_mean\": attn_mean,\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def train_one_experiment(cfg: Config,\n",
        "                         pe_type: str,\n",
        "                         num_generators: int,\n",
        "                         exp_name: str,\n",
        "                         strict_model=True,\n",
        "                         load_optim=False):\n",
        "    device = cfg.device\n",
        "    train_loader, test_loader = get_dataloaders(cfg)\n",
        "\n",
        "    model = ViTWithPE(cfg, pe_type=pe_type, num_generators=num_generators).to(device)\n",
        "\n",
        "    if \"mg\" in pe_type:\n",
        "        base_params = []\n",
        "        mg_params = []\n",
        "        for name, p in model.named_parameters():\n",
        "            if (\"cayley_pe\" in name) or (\"mg_alpha\" in name):\n",
        "                mg_params.append(p)\n",
        "            else:\n",
        "                base_params.append(p)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            [\n",
        "                {\n",
        "                    \"params\": base_params,\n",
        "                    \"lr\": cfg.lr,\n",
        "                    \"weight_decay\": cfg.weight_decay,\n",
        "                    \"betas\": (0.9, 0.95),\n",
        "                },\n",
        "                {\n",
        "                    \"params\": mg_params,\n",
        "                    \"lr\": cfg.lr * 1.5,\n",
        "                    \"weight_decay\": 0.0,\n",
        "                    \"betas\": (0.9, 0.95),\n",
        "                },\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=cfg.lr,\n",
        "            weight_decay=cfg.weight_decay,\n",
        "            betas=(0.9, 0.95),\n",
        "        )\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device == \"cuda\"))\n",
        "\n",
        "    ckpt_path = os.path.join(cfg.ckpt_dir, f\"{exp_name}.pt\")\n",
        "    start_epoch = 0\n",
        "    best_acc = 0.0\n",
        "\n",
        "    if os.path.exists(ckpt_path):\n",
        "        start_epoch, best_acc = load_checkpoint(ckpt_path, model, optimizer, device, strict_model, load_optim)\n",
        "\n",
        "    # lr scheduling\n",
        "    steps_per_epoch = len(train_loader)\n",
        "    total_steps = steps_per_epoch * cfg.max_epochs\n",
        "    warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "    def lr_lambda(step: int):\n",
        "        if step < warmup_steps:\n",
        "            return float(step + 1) / float(max(1, warmup_steps))\n",
        "        # cosine decay from 1 -> 0\n",
        "        progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer, lr_lambda=lr_lambda\n",
        "    )\n",
        "\n",
        "    train_start = time.perf_counter()\n",
        "\n",
        "    for epoch in range(start_epoch, cfg.max_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.amp.autocast(\"cuda\", enabled=(device == \"cuda\")):\n",
        "                logits = model(images)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            batch_size = labels.size(0)\n",
        "            running_loss += loss.item() * batch_size\n",
        "            total += batch_size\n",
        "            preds = logits.argmax(dim=-1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = correct / total\n",
        "        val_loss, val_acc = evaluate(model, test_loader, device)\n",
        "\n",
        "        print(f\"[{exp_name}] Epoch {epoch+1}/{cfg.max_epochs} \"\n",
        "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if getattr(model.blocks[0].attn, \"mg_alpha\", None) is not None:\n",
        "            alpha = torch.sigmoid(model.blocks[0].attn.mg_alpha).item()\n",
        "            print(f\"[MG alpha] {alpha:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            save_checkpoint(ckpt_path, model, optimizer, epoch, best_acc)\n",
        "\n",
        "        elif (epoch + 1) % cfg.save_every == 0:\n",
        "            save_checkpoint(ckpt_path, model, optimizer, epoch, best_acc)\n",
        "\n",
        "    train_end = time.perf_counter()\n",
        "    total_train_time = train_end - train_start\n",
        "\n",
        "    print(f\"[{exp_name}] Best Val Acc: {best_acc:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    infer_start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            _ = model(images)\n",
        "    infer_end = time.perf_counter()\n",
        "    total_infer_time = infer_end - infer_start\n",
        "\n",
        "    print(f\"[{exp_name}] Training time (s): {total_train_time:.2f}\")\n",
        "    print(f\"[{exp_name}] Inference time (s, 1x test loader): {total_infer_time:.2f}\")\n",
        "\n",
        "    if pe_type in (\"cayley\", \"mg\", \"cayley_sparse\", \"mg_sparse\"):\n",
        "        with torch.no_grad():\n",
        "            cayley_pe = None\n",
        "            for blk in model.blocks:\n",
        "                if hasattr(blk.attn, \"cayley_pe\") and blk.attn.cayley_pe is not None:\n",
        "                    cayley_pe = blk.attn.cayley_pe\n",
        "                    break\n",
        "            if cayley_pe is not None:\n",
        "                metrics = compute_relative_position_metrics(\n",
        "                    cayley_pe,\n",
        "                    max_positions=min(64, model.num_patches + 1),\n",
        "                    n_attn_samples=500,\n",
        "                )\n",
        "                print(f\"[{exp_name}] Relative-position metrics:\")\n",
        "                for k, v in metrics.items():\n",
        "                    if v is not None:\n",
        "                        print(f\"   {k}: {v:.6e}\")\n",
        "                    else:\n",
        "                        print(f\"   {k}: None (not applicable)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "7. Main: run experiments\n",
        "\"\"\"\n",
        "\n",
        "EXPERIMENTS = [\n",
        "    {\"pe_type\": \"rope\",   \"num_generators\": 0, \"name\": f\"{cfg.dataset}_rope\"},\n",
        "    {\"pe_type\": \"cayley\", \"num_generators\": 1, \"name\": f\"{cfg.dataset}_cayley1\"},\n",
        "    {\"pe_type\": \"mg\",     \"num_generators\": 1, \"name\": f\"{cfg.dataset}_mg1\"},\n",
        "    {\"pe_type\": \"mg\",     \"num_generators\": 4, \"name\": f\"{cfg.dataset}_mg4\"},\n",
        "    {\"pe_type\": \"cayley_sparse\", \"num_generators\": 1, \"name\": f\"{cfg.dataset}_cayley1_sparse\"},\n",
        "    {\"pe_type\": \"mg_sparse\",     \"num_generators\": 4, \"name\": f\"{cfg.dataset}_mg4_sparse\"}\n",
        "]\n",
        "\n",
        "strict_model = True\n",
        "load_optim = False\n",
        "\n",
        "for exp in EXPERIMENTS:\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Running experiment: {exp['name']} \"\n",
        "          f\"(pe_type={exp['pe_type']}, L={exp['num_generators']})\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    train_one_experiment(\n",
        "        cfg,\n",
        "        pe_type=exp[\"pe_type\"],\n",
        "        num_generators=exp[\"num_generators\"],\n",
        "        exp_name=exp[\"name\"],\n",
        "        strict_model=strict_model,\n",
        "        load_optim=load_optim\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuLPDmtdLjk0",
        "outputId": "9b41505b-9ca0-4ebb-e31c-6798ad044970"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "Running experiment: CIFAR10_rope (pe_type=rope, L=0)\n",
            "------------------------------------------------------------\n",
            "[CIFAR10_rope] Best Val Acc: 0.8204\n",
            "[CIFAR10_rope] Training time (s): 0.00\n",
            "[CIFAR10_rope] Inference time (s, 1x test loader): 1.51\n",
            "------------------------------------------------------------\n",
            "Running experiment: CIFAR10_cayley1 (pe_type=cayley, L=1)\n",
            "------------------------------------------------------------\n",
            "[CIFAR10_cayley1] Best Val Acc: 0.8602\n",
            "[CIFAR10_cayley1] Training time (s): 0.00\n",
            "[CIFAR10_cayley1] Inference time (s, 1x test loader): 1.75\n",
            "[CIFAR10_cayley1] Relative-position metrics:\n",
            "   rel_rot_error_mean: 7.760215e-02\n",
            "   rel_rot_error_max: 2.704786e-01\n",
            "   comm_mean: None (not applicable)\n",
            "   comm_max: None (not applicable)\n",
            "   ortho_error_mean: 3.048992e-06\n",
            "   ortho_error_max: 3.848920e-06\n",
            "   smoothness_mean: 7.500699e-02\n",
            "   attn_rel_error_mean: 2.091826e+00\n",
            "------------------------------------------------------------\n",
            "Running experiment: CIFAR10_mg1 (pe_type=mg, L=1)\n",
            "------------------------------------------------------------\n",
            "[CIFAR10_mg1] Best Val Acc: 0.8628\n",
            "[CIFAR10_mg1] Training time (s): 0.00\n",
            "[CIFAR10_mg1] Inference time (s, 1x test loader): 2.41\n",
            "[CIFAR10_mg1] Relative-position metrics:\n",
            "   rel_rot_error_mean: 5.307786e-01\n",
            "   rel_rot_error_max: 1.591872e+00\n",
            "   comm_mean: None (not applicable)\n",
            "   comm_max: None (not applicable)\n",
            "   ortho_error_mean: 3.046684e-06\n",
            "   ortho_error_max: 3.855640e-06\n",
            "   smoothness_mean: 1.210380e-01\n",
            "   attn_rel_error_mean: 3.009198e+00\n",
            "------------------------------------------------------------\n",
            "Running experiment: CIFAR10_mg4 (pe_type=mg, L=4)\n",
            "------------------------------------------------------------\n",
            "[CIFAR10_mg4] Best Val Acc: 0.8698\n",
            "[CIFAR10_mg4] Training time (s): 0.00\n",
            "[CIFAR10_mg4] Inference time (s, 1x test loader): 2.54\n",
            "[CIFAR10_mg4] Relative-position metrics:\n",
            "   rel_rot_error_mean: 3.574533e+00\n",
            "   rel_rot_error_max: 7.403358e+00\n",
            "   comm_mean: 1.870625e-03\n",
            "   comm_max: 1.988781e-03\n",
            "   ortho_error_mean: 3.596901e-06\n",
            "   ortho_error_max: 5.190908e-06\n",
            "   smoothness_mean: 2.515605e-01\n",
            "   attn_rel_error_mean: 5.986518e+00\n",
            "------------------------------------------------------------\n",
            "Running experiment: CIFAR10_cayley1_sparse (pe_type=cayley_sparse, L=1)\n",
            "------------------------------------------------------------\n",
            "[CIFAR10_cayley1_sparse] Best Val Acc: 0.8680\n",
            "[CIFAR10_cayley1_sparse] Training time (s): 0.00\n",
            "[CIFAR10_cayley1_sparse] Inference time (s, 1x test loader): 1.75\n",
            "[CIFAR10_cayley1_sparse] Relative-position metrics:\n",
            "   rel_rot_error_mean: 2.486794e-02\n",
            "   rel_rot_error_max: 8.892528e-02\n",
            "   comm_mean: None (not applicable)\n",
            "   comm_max: None (not applicable)\n",
            "   ortho_error_mean: 2.150117e-06\n",
            "   ortho_error_max: 2.527567e-06\n",
            "   smoothness_mean: 5.153546e-02\n",
            "   attn_rel_error_mean: 1.298060e+00\n",
            "------------------------------------------------------------\n",
            "Running experiment: CIFAR10_mg4_sparse (pe_type=mg_sparse, L=4)\n",
            "------------------------------------------------------------\n",
            "[CIFAR10_mg4_sparse] Best Val Acc: 0.8658\n",
            "[CIFAR10_mg4_sparse] Training time (s): 0.00\n",
            "[CIFAR10_mg4_sparse] Inference time (s, 1x test loader): 2.54\n",
            "[CIFAR10_mg4_sparse] Relative-position metrics:\n",
            "   rel_rot_error_mean: 2.234426e+00\n",
            "   rel_rot_error_max: 5.511654e+00\n",
            "   comm_mean: 1.056334e-03\n",
            "   comm_max: 1.103897e-03\n",
            "   ortho_error_mean: 2.099764e-06\n",
            "   ortho_error_max: 2.437897e-06\n",
            "   smoothness_mean: 2.237356e-01\n",
            "   attn_rel_error_mean: 5.004286e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QTdcHZEgOeHw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}